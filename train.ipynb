{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from swift.llm import sft_main, SftArguments, ModelType, DatasetName\n",
    "\n",
    "\n",
    "sft_main(SftArguments(model_type=ModelType.qwen2_audio_7b_instruct,\n",
    "                      model_id_or_path=None,\n",
    "                      dataset=[DatasetName.aishell1_zh_mini]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果是本地路径需要增加：`--model_id_or_path <local_path>` （If it is a local path, it needs to be added.）\n",
    "NPROC_PER_NODE=4 CUDA_VISIBLE_DEVICES=0,1,2,3 swift sft \\\n",
    "    --model_type qwen2-audio-7b-instruct \\\n",
    "    --dataset aishell1-zh-mini \\\n",
    "    --deepspeed default-zero2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset可选，如果不指定，则会从dataset中切出一部分数据集作为验证集\n",
    "    --dataset train.jsonl \\\n",
    "    --val_dataset val.jsonl \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 swift infer \\\n",
    "    --ckpt_dir output/qwen2-audio-7b-instruct/vx-xxx/checkpoint-xxx \\\n",
    "    --load_dataset_config true\n",
    "\n",
    "# merge-lora and inference\n",
    "CUDA_VISIBLE_DEVICES=0 swift infer \\\n",
    "    --ckpt_dir output/qwen2-audio-7b-instruct/vx-xxx/checkpoint-xxx \\\n",
    "    --load_dataset_config true --merge_lora true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
